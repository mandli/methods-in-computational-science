{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Parallel Computing\n",
    "\n",
    "## Types of Operations\n",
    "\n",
    " - Pleasing (trivial) parallel sections\n",
    " - Reductions\n",
    " - Tasks\n",
    " \n",
    "## Types of Parallel Computing\n",
    "\n",
    " - Cloud\n",
    " - Single Node (shared memory)\n",
    " - Multi-Node (distributed memory)\n",
    " - GPU (king of shared memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example: Matrix-Matrix Multiplication\n",
    "\n",
    "To start our discussion let us consider the algorithm for matrix-matrix multiplication which algorithmically looks like\n",
    "```\n",
    "do i=1:N\n",
    "    do j=1:N\n",
    "        do k=1:N\n",
    "            C[i, j] = C[i, j] + A[i, k] * B[k, j]\n",
    "        end do\n",
    "    end do\n",
    "end do\n",
    "```\n",
    "\n",
    "Consider the follow approaches to this problem:\n",
    "1. Matrix multiplication via a GCC (Fortran) intrinsic.\n",
    "1. Straight forward three-loop multiplication\n",
    "1. Parallelized double-loop using BLAS intrinsic\n",
    "1. BLAS intrinsic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```fortran\n",
    "real function matrix_multiply_test(N,method)\n",
    "\n",
    "    use mod_rand\n",
    "    implicit none\n",
    "    \n",
    "    external DGEMM,DDOT\n",
    "    \n",
    "    double precision :: DDOT\n",
    "    integer, intent(in) :: N,method\n",
    "    integer :: start,finish,count_rate\n",
    "    double precision, dimension(:,:), allocatable :: A,B,C\n",
    "    \n",
    "    ! Local\n",
    "    integer :: i,j,k\n",
    "    \n",
    "    ! Create the random arrays\n",
    "    call init_random_seed()\n",
    "    allocate(A(N,N),B(N,N),C(N,N))\n",
    "    call random_number(A)\n",
    "    call random_number(B)\n",
    "    \n",
    "    ! Start the timer and start multiplying\n",
    "    call system_clock(start,count_rate)\n",
    "    select case(method)\n",
    "        case(1) ! Default method provided as an intrinsic method\n",
    "            C = matmul(A,B)\n",
    "        case(2) ! Simple three loop multiplication\n",
    "            !$OMP parallel do private(j,k)\n",
    "            do i=1,N\n",
    "                do j=1,N\n",
    "                    do k=1,N\n",
    "                        C(i,j) = C(i,j) + A(i,k) * B(k,j)\n",
    "                    enddo\n",
    "                enddo\n",
    "            enddo\n",
    "        case(3) ! OpenMP parallelized double loop\n",
    "            !$OMP parallel do private(j)\n",
    "            do i=1,N\n",
    "                do j=1,N\n",
    "                    C(i,j) = DDOT(N, A(i,:), 1, B(:,j), 1)\n",
    "                enddo\n",
    "            enddo\n",
    "        case(4) ! BLAS Routine call\n",
    "            ! call DGEMM(transa,transb,l,n,m,alpha,a,lda,b,ldb,beta,c,ldc)\n",
    "            call DGEMM('N', 'N', N, N, N, 1.d0, A, N, B, N, 0.d0, C, N)\n",
    "        case default\n",
    "            print *, \"***ERROR*** Invalid multiplication method!\"\n",
    "            matrix_multiply_test = -1\n",
    "            return\n",
    "    end select\n",
    "    call system_clock(finish,count_rate)\n",
    "    \n",
    "    matrix_multiply_test = float(finish - start) / float(count_rate)\n",
    "    \n",
    "end function matrix_multiply_test\n",
    "    \n",
    "program matrix_multiply\n",
    "    \n",
    "    use omp_lib\n",
    "\n",
    "    implicit none\n",
    "    \n",
    "    integer :: N, method, threads\n",
    "    character(len=10) :: input_N, input_method, input_threads\n",
    "    real :: matrix_multiply_test, time\n",
    "    \n",
    "    select case(iargc())\n",
    "        case(0)\n",
    "            N = 1000\n",
    "            method = 1\n",
    "            threads = 1\n",
    "        case(1)\n",
    "            call getarg(1,input_N)\n",
    "            read(input_N,'(I10)') N\n",
    "            method = 1\n",
    "        case(2)\n",
    "            call getarg(1,input_N)\n",
    "            call getarg(2,input_method)\n",
    "            read(input_N,'(I10)') N\n",
    "            read(input_method,'(I10)') method\n",
    "        case(3)\n",
    "            call getarg(1,input_N)\n",
    "            call getarg(2,input_method)\n",
    "            call getarg(3,input_threads)\n",
    "            read(input_N,'(I10)') N\n",
    "            read(input_method,'(I10)') method\n",
    "            read(input_threads,'(I10)') threads\n",
    "        case default\n",
    "            print *, \"***ERROR*** Too many arguments!\"\n",
    "            stop\n",
    "    end select\n",
    "    \n",
    "    !$ call omp_set_num_threads(threads)\n",
    "\n",
    "    time = matrix_multiply_test(N, method)\n",
    "    \n",
    "    print '(\"Timing for \",i5,\"x\",i5,\" matrices: \",f10.5,\" s\")',N,N,time\n",
    "    \n",
    "end program matrix_multiply\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Results\n",
    "\n",
    "Based on $1000 \\times 1000$ matrix-matrix multiply compiled with `gfortran` version 6.3.0 with the compile time flags `-O3 -funroll-loops -finline-functions -fdefault-real-8 -fopenmp`.\n",
    "\n",
    "\n",
    "Method                           | No-Threads            | Threaded\n",
    "---------------------------------|-----------------------|---------------------------\n",
    "Default mat_mult function        |            35.79600 s |                36.19100 s\n",
    "3 loop multiplication            |            39.24700 s |                10.04000 s                   \n",
    "Double loop (internal BLAS)      |             6.80500 s |                 1.76600 s                   \n",
    "BLAS Routine call                |             0.00300 s |                 0.00300 s                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelization\n",
    "\n",
    "Parallelization is one of the primary ways we can increase performance on today's computing architectures.  There are 2+1 major types of parallelization paradigms:\n",
    " - Shared memory - each pipeline can access the memory for the entire problem\n",
    " - Distributed memory - each pipeline can only access part of the memory for the entire problem\n",
    " - Hybrid parallelism - use both..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Shared Memory\n",
    "\n",
    " - Basic construct is a *thread* - each thread has a pipeline and in the simplest case each core runs one thread\n",
    " - OpenMP, CUDA, OpenCL, OpenACC\n",
    " - Single nodes on a cluster, GPU, Xeon Phi, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distributed Memory\n",
    "\n",
    " - Basic contruct is a *process* \n",
    " - Each process is memory local but can communicate to other processes either on the same CPU or across a network\n",
    " - Each process can have multiple threads (hybrid parallelism)\n",
    " - MPI is most common\n",
    " - Clusters, super-computers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Scalability\n",
    "\n",
    "Measures of parallel performance:\n",
    "\n",
    " - Strong Scaling:  Execution time decreases inversely proportional to the number of processes\n",
    "   - Fixed size problem\n",
    " - Weak Scaling: Execution time remains constant as problem size and processes number are increased proportionally\n",
    "   - Variable size problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
